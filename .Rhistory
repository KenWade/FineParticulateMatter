activity_start_date  <- NULL
activity_type        <- NULL
for (i in 1:length(my_activity_list_raw)) {
activity_id[i]          <- my_activity_list_raw[[i]]$id
#    activity_athlete[i]     <- my_activity_list_raw[[i]]$athlete
activity_name[i]        <- my_activity_list_raw[[i]]$name
activity_moving_time[i] <- my_activity_list_raw[[i]]$moving_time
activity_start_date[i]  <- my_activity_list_raw[[i]]$start_date
activity_type[i]        <- my_activity_list_raw[[i]]$type
}
#my_activity_list <- data.frame(activity_id, activity_athlete, activity_type, activity_name, activity_moving_time, activity_start_date, stringsAsFactors = FALSE)
my_activity_list <- data.frame(activity_id, activity_type, activity_name, activity_moving_time, activity_start_date, stringsAsFactors = FALSE)
my_activity_list_raw <- get_activity_list(stoken, id = my_id)
tmp <- get_activity_list(stoken)
my_activity_list_raw == tmp
source("extra.R")
my_id <- '1294941'
app_name <- 'OldManRider'
app_client_id  <- '8991'
app_secret <- '58c37ac5ca754923d222da0d457947f878787828'
access_token <- 'f94e8c67b36f2ebc2e03daceecba3a6593cd55de'
#####
#
# Create the Authentication Token
#
#       Example Code...
#
#####
stoken <- httr::config(token = strava_oauth(app_name, app_client_id, app_secret, app_scope = "view_private", cache = TRUE))
#####
#
# Gather Strava Data
#
#       Example Code...
#
#####
my_info <- get_athlete(stoken, id = my_id)
my_activity_list_raw <- get_activity_list(stoken, id = my_id)
activity_id          <- NULL
#activity_athlete     <- NULL
activity_name        <- NULL
activity_moving_time <- NULL
activity_start_date  <- NULL
activity_type        <- NULL
for (i in 1:length(my_activity_list_raw)) {
activity_id[i]          <- my_activity_list_raw[[i]]$id
#    activity_athlete[i]     <- my_activity_list_raw[[i]]$athlete
activity_name[i]        <- my_activity_list_raw[[i]]$name
activity_moving_time[i] <- my_activity_list_raw[[i]]$moving_time
activity_start_date[i]  <- my_activity_list_raw[[i]]$start_date
activity_type[i]        <- my_activity_list_raw[[i]]$type
}
#my_activity_list <- data.frame(activity_id, activity_athlete, activity_type, activity_name, activity_moving_time, activity_start_date, stringsAsFactors = FALSE)
my_activity_list <- data.frame(activity_id, activity_type, activity_name, activity_moving_time, activity_start_date, stringsAsFactors = FALSE)
stoken <- httr::config(token = strava_oauth(app_name, app_client_id, app_secret, app_scope = "view_private", cache = TRUE))
Wa
stoken <- httr::config(token = strava_oauth(app_name, app_client_id, app_secret, app_scope = "view_private", cache = TRUE))
my_activity_list_raw <- get_activity_list(stoken, id = my_id)
x <- athl_fun(my_id)
x
x <- athlind(my_id)
x <- athlind_fun(my_id)
x
get_KOMs(my_id, stoken)
get_basic('https://strava.com/api/v3/athlete', stoken)
get_efforts_list(stoken, id = my_id)
x <- get_efforts_list(stoken, id = my_id)
head(x)
x$athlete$id
x[[1]]$athlete$id
length(x)
for (i in 1:length(x)) {}
y = NULL
for (i in 1:length(x)) {
y[i] <- x[[i]]$athlete$id
}
y
my_id in y
y == my_id
sum(y)
sum(as.numeric(y))
my_id %in% y
x <- get_efforts_list(stoken, id = 1294941)
y = NULL
for (i in 1:length(x)) {
y[i] <- x[[i]]$athlete$id
}
my_id %in% y
z <-get_segment(stoken, id=my_id, request="all_efforts")
z <-get_segment(stoken, id=10550853396, request="all_efforts")
z <-get_segment(stoken, id=10550853396, request="all_efforts")
z <-get_segment(stoken, id=438918416, request="all_efforts")
plot?
?plot
colors()
x <- rnorm(100)
hist(x)
x <- rnorm(100000)
hist(x)
x <- rnorm(100)
y <- rnorm(100)
plot(x,y)
z <- rnorm(100)
plot(x,z)
plot(x,y)
par(mar = c(2,2,2,2))
plot(x,y)
par(mar = c(4,4,2,2))
plot(x,y)
plot(x,y, pch=20)
plot(x,y, pch=2)
plot(x,y, pch=3)
example(points())
example(points
)
x <- rnorm(100)
y <- rnorm(100)
plot(x,y, pch=3)
title("ScatterPlot")
text(-2.-2, "a;lsdkfj")
text(-2.-2, "alsdkfj")
text(-2.-2, "a")
plot(x,y, pch=3)
title("ScatterPlot")
text(-2,-2, "a")
legend("topleft", legend = "Data")
legend("topleft", legend = "Data", pch = 20)
fit <- lm(y~x)
abline(fit)
abline(fit, lwd=3)
abline(fit, lwd=3, col = "blue")
plot(x,y, pch=3, xlab = "Weight", ylab = "Height", main = "Scatter Plot")
legend("topright", legend = "Data", pch = 20)
abline(fit, lwd=3, col = "salmon")
z <-rpois(100,2)
par(mfrow=c(2,1))
plot(x,y)
plot(x,z)
par("mar")
par("mar"=c(2,2,1,1))
plot(x,y)
plot(x,z)
par(mfrow=c(2,1))
plot(x,y)
plot(x,z)
par(mfrow=c(1,2))
plot(x,y)
plot(x,z)
par(mfrow=c(2,2))
plot(x,y)
plot(x,z)
plot(y,z)
plot(z,x)
par(mfrow=c(1,1))
y = x+rnorm(100)
g = gl(2,50)
g = gl(2,50, lables = c("Male", "Female"00))
g = gl(2,50, lables = c("Male", "Female"))
g = gl(2,50, labels  = c("Male", "Female"))
plot(x,y)
par("mar" = c(4,4,2,2))
plot(x,y)
str(g)
plot(x,y, type="n")
points(x[g=="Male"])
points(x[g=="Male"], col="green")
x[g=="Female"]
x[g=="Male"]
points(x[g=="Male"], y[g=="Male", col="green")
points(x[g=="Male"], y[g=="Male"], col="green")
points(x[g=="Female"], y[g=="Female"], col="steel")
points(x[g=="Female"], y[g=="Female"], col="bluesteel")
colors()
points(x[g=="Female"], y[g=="Female"], col="steelblue")
points(x[g=="Female"], y[g=="Female"], col="steelblue", pch=19)
####
#
#   Exploratory Data Analysis (class.coursera.org/exdata-035)
#
#   Making Plots
#
#       Our overall goal here is simply to examine how household energy usage varies over a 2-day period in
#       February, 2007. Your task is to reconstruct the following plots below, all of which were constructed using
#       the base plotting system.
#
####
#
#   Setup Libraries
#
library(lubridate)
hpc_filename   <- "household_power_consumption.txt"
hpc_colClasses <- c("character",  "character", "numeric", "numeric", "numeric", "numeric", "numeric", "numeric", "numeric")
hpc_nastrings  <- "?"
minDate <- as.Date("2007-02-01", "%Y-%m-%d")
maxDate <- as.Date("2007-02-02", "%Y-%m-%d")
####
#
#    Read in the Electric power consumption data from the working directory
#
#        Find the size of the data frame object and consider the implecations...
#
#           Input file size:        129,845KB = 132961280 bytes ~ 130MB
#           Data Frame dimensions:  2075259 obs. of  9 variables
#           Data Frame object.size: 83644688 bytes ~ 80MB
#               7.118858684894539 bytes per variable per observation in the data file
#               4.478406898715882 bytes per variable per observation in the data frame
#
# Data daken from UCI Machine Learning Repository: https://archive.ics.uci.edu/ml/datasets/Individual+household+electric+power+consumption
#
# Downloaded from: https://d396qusza40orc.cloudfront.net/exdata%2Fdata%2Fhousehold_power_consumption.zip
epcFull <- read.table(hpc_filename, header=TRUE, sep=";", colClasses = hpc_colClasses, na.strings = hpc_nastrings)
objectsize = object.size(epcFull)
####
#
#   Convert date and time to R date and time classes and
#   Convert all other variables to numbers
#
epcFull$DateTime <- strptime(paste(epcFull$Date, epcFull$Time, sep = " "), "%d/%m/%Y %H:%M:%S")
####
#
#   Select only the dates of interest
#
epc <- epcFull[(as.Date(epcFull$DateTime) >= minDate) & (as.Date(epcFull$DateTime) <= maxDate), ]
####
#
#   Exploratory Data Analysis (class.coursera.org/exdata-035)
#
#   Making Plots
#
#       Our overall goal here is simply to examine how household energy usage varies over a 2-day period in
#       February, 2007. Your task is to reconstruct the following plots below, all of which were constructed using
#       the base plotting system.
#
####
#
#   Setup Libraries
#
library(lubridate)
####
#
#    Read in the Electric power consumption data from the working directory
#
#       As an side detail suggusted in the project description...
#           find the size of the data frame object and consider the implecations.
#
#               Input file size:        132,960,755 bytes ~ 130MB
#               Data Frame object.size: 149,581,752 bytes ~ 142MB
#               Data Frame dimensions:  2075259 obs. of  9 variables
#                   7.12 bytes per variable per observation in the data file
#                   8.00 bytes per variable per observation in the data frame
#
# Data daken from UCI Machine Learning Repository: https://archive.ics.uci.edu/ml/datasets/Individual+household+electric+power+consumption
#
# Downloaded from: https://d396qusza40orc.cloudfront.net/exdata%2Fdata%2Fhousehold_power_consumption.zip
get_household_power_consumption_data <- function() {
hpc_filename   <- "household_power_consumption.txt"
hpc_colClasses <- c("character",  "character", "numeric", "numeric", "numeric", "numeric", "numeric", "numeric", "numeric")
hpc_nastrings  <- "?"
minDate <- as.Date("2007-02-01", "%Y-%m-%d")
maxDate <- as.Date("2007-02-02", "%Y-%m-%d")
epcFull <- read.table(hpc_filename, header=TRUE, sep=";", colClasses = hpc_colClasses, na.strings = hpc_nastrings)
hpc_filesize   <- file.size(hpc_filename)
hpc_objectsize <- object.size(epcFull)
bytes_per_variable_per_observation_in_datafile <- hpc_filesize / ncol(epcFull) / nrow(epcFull)
bytes_per_variable_per_observation_in_object   <- hpc_objectsize / ncol(epcFull) / nrow(epcFull)
####
#
#   Convert date and time to R date and time classes and
#
epcFull$DateTime <- strptime(paste(epcFull$Date, epcFull$Time, sep = " "), "%d/%m/%Y %H:%M:%S")
####
#
#   Select only the dates of interest
#
epc <- subset(epcFull, (as.Date(epcFull$DateTime) >= minDate) & (as.Date(epcFull$DateTime) <= maxDate))
return(epc)
}
#######################################################################
#
# Make Plot1
#
#######################################################################
epc <- get_household_power_consumption_data()
png(filename = "plot1.png", width = 480, height = 480, units = "px")
hist(epc$Global_active_power, main = "Global Active Power", xlab = "Global Active Power (kilowatts)", col = "red", breaks = 12)
dev.off()
library(nlme)
library(lattice)
xyplot(weight ~ Time | Diet, BodyWeight)
str(Diet)
str(BodyWeight)
axis()
library(datasets)
data(airquality)
qplot(Wind, Ozone, data = airquality, facets = . ~ factor(Month))
library(ggplot2)
qplot(Wind, Ozone, data = airquality, facets = . ~ factor(Month))
airquality = transform(airquality, Month = factor(Month))
qplot(Wind, Ozone, data = airquality, facets = . ~ Month)
qplot(Wind, Ozone, data = airquality)
qplot(Wind, Ozone, data = airquality, geom = "smooth")
airquality = transform(airquality, Month = factor(Month))
qplot(Wind, Ozone, data = airquality, facets = . ~ Month)
library(ggplot2)
g <- ggplot(movies, aes(votes, rating))
print(g)
qplot(votes, rating, data = movies)
qplot(votes, rating, data = movies, panel = panel.loess)
qplot(votes, rating, data = movies, smooth = "loess")
qplot(votes, rating, data = movies) + geom_smooth()
qplot(votes, rating, data = movies) + stats_smooth("loess")
####
#
#   plot1.R
#
#   Exploratory Data Analysis (class.coursera.org/exdata-035)
#
#   Course Project 2 - Fine particulate matter
#
#       The overall goal of this assignment is to explore the National Emissions Inventory database and see what it say
#       about fine particulate matter pollution in the United states over the 10-year period 1999-2008. You may use any
#       R package you want to support your analysis.
#
#   Question:   Have total emissions from PM2.5 decreased in the United States from 1999 to 2008?
#
#               Using the base plotting system, make a plot showing the total PM2.5 emission from all sources for each of
#               the years 1999, 2002, 2005, and 2008.
#
#   Answer:     YES. total emissions from PM2.5 have decreased in the United States from 1999 to 2008.
####
#
#   Setup Libraries, Directories, and URLs
#
#library(dplyr)
setwd("C:/Users/Ken/Documents/Ken/Continuing Education/Johns Hopkins School of Public Health - Data Science 4 - Exploratory Data Analysis/FineParticulateMatter")
projectDataURL <- "https://d396qusza40orc.cloudfront.net/exdata%2Fdata%2FNEI_data.zip"
####
#
#    Read in the Course Project 2 data files
## Create the data folder
if(!file.exists("data")) {
dir.create("data")
print("Created data folder.")
}
## Download the zip file for the course
if(!file.exists("./data/data.zip")) {
print("Downloading data.zip...")
download.file(projectDataURL, destfile = "./data/data.zip", mode = "wb")
print("Downloading data.zip completed.")
}
if(!file.exists("./data/zipcontents")) {
print("Unzipping data.zip...")
unzip("./data/data.zip", exdir="./data/zipcontents")
print("Unzipping data.zip completed.")
}
## This first line will likely take a few seconds. Be patient!
print("Reading data files.")
NEI <- readRDS("./data/zipcontents/summarySCC_PM25.rds")
SCC <- readRDS("./data/zipcontents/Source_Classification_Code.rds")
print("Reading data files completed.")
####
#
# Plot 1
#
emissionsByYear <- aggregate(NEI$Emissions, by = list(NEI$year), FUN=sum, na.rm=TRUE)
names(emissionsByYear) <- c("year", "total")
png(filename = "plot1.png", width = 480, height = 480, units = "px")
plot(emissionsByYear$year, emissionsByYear$total/1000, type="b", main="Total PM2.5 Emission From All Sources",
xlab="Year", ylab="Total Emissions (1,000 Tons)", ylim=c(0, max(emissionsByYear$total/1000)))
dev.off()
####
#
#   plot2.R
#
#   Exploratory Data Analysis (class.coursera.org/exdata-035)
#
#   Course Project 2 - Fine particulate matter
#
#       The overall goal of this assignment is to explore the National Emissions Inventory database and see what it say
#       about fine particulate matter pollution in the United states over the 10-year period 1999-2008. You may use any
#       R package you want to support your analysis.
#
#   Question:   Have total emissions from PM2.5 decreased in Baltimore City, Maryland (fips=="24510") from 1999 to 2008?
#
#               Use the base plotting system to make a plot answering this question.
#
#   Answer:     YES. total emissions from PM2.5 have decreased in  Baltimore City from 1999 to 2008.
#
####
#
#   Setup Libraries, Directories, and URLs
#
setwd("C:/Users/Ken/Documents/Ken/Continuing Education/Johns Hopkins School of Public Health - Data Science 4 - Exploratory Data Analysis/FineParticulateMatter")
projectDataURL <- "https://d396qusza40orc.cloudfront.net/exdata%2Fdata%2FNEI_data.zip"
####
#
#    Read in the Course Project 2 data files
## Create the data folder
if(!file.exists("data")) {
dir.create("data")
print("Created data folder.")
}
## Download the zip file for the course
if(!file.exists("./data/data.zip")) {
print("Downloading data.zip...")
download.file(projectDataURL, destfile = "./data/data.zip", mode = "wb")
print("Downloading data.zip completed.")
}
if(!file.exists("./data/zipcontents")) {
print("Unzipping data.zip...")
unzip("./data/data.zip", exdir="./data/zipcontents")
print("Unzipping data.zip completed.")
}
## This first line will likely take a few seconds. Be patient!
print("Reading data files.")
NEI <- readRDS("./data/zipcontents/summarySCC_PM25.rds")
SCC <- readRDS("./data/zipcontents/Source_Classification_Code.rds")
print("Reading data files completed.")
####
#
# Plot 2
#
emissionsByYear <- aggregate(NEI$Emissions, by = list(NEI$year, NEI$fips), FUN=sum, na.rm=TRUE)
names(emissionsByYear) <- c("year", "fips", "total")
emissionsByYear_BaltimoreCity <- emissionsByYear[emissionsByYear$fips == "24510",]
png(filename = "plot2.png", width = 480, height = 480, units = "px")
plot(emissionsByYear_BaltimoreCity$year, emissionsByYear_BaltimoreCity$total/1000, type="b",
main="Baltimore City Total PM2.5 Emission From All Sources",
xlab="Year", ylab="Total Emissions (1,000 Tons)", ylim=c(0, max(emissionsByYear_BaltimoreCity$total/1000)))
dev.off()
####
#
#   plot2.R
#
#   Exploratory Data Analysis (class.coursera.org/exdata-035)
#
#   Course Project 2 - Fine particulate matter
#
#       The overall goal of this assignment is to explore the National Emissions Inventory database and see what it say
#       about fine particulate matter pollution in the United states over the 10-year period 1999-2008. You may use any
#       R package you want to support your analysis.
#
#   Question:   Have total emissions from PM2.5 decreased in Baltimore City, Maryland (fips=="24510") from 1999 to 2008?
#
#               Use the base plotting system to make a plot answering this question.
#
#   Answer:     YES. total emissions from PM2.5 have decreased in  Baltimore City from 1999 to 2008.
#
####
#
#   Setup Libraries, Directories, and URLs
#
setwd("C:/Users/Ken/Documents/Ken/Continuing Education/Johns Hopkins School of Public Health - Data Science 4 - Exploratory Data Analysis/FineParticulateMatter")
projectDataURL <- "https://d396qusza40orc.cloudfront.net/exdata%2Fdata%2FNEI_data.zip"
####
#
#    Read in the Course Project 2 data files
## Create the data folder
if(!file.exists("data")) {
dir.create("data")
print("Created data folder.")
}
## Download the zip file for the course
if(!file.exists("./data/data.zip")) {
print("Downloading data.zip...")
download.file(projectDataURL, destfile = "./data/data.zip", mode = "wb")
print("Downloading data.zip completed.")
}
if(!file.exists("./data/zipcontents")) {
print("Unzipping data.zip...")
unzip("./data/data.zip", exdir="./data/zipcontents")
print("Unzipping data.zip completed.")
}
## This first line will likely take a few seconds. Be patient!
print("Reading data files.")
NEI <- readRDS("./data/zipcontents/summarySCC_PM25.rds")
SCC <- readRDS("./data/zipcontents/Source_Classification_Code.rds")
print("Reading data files completed.")
####
#
# Plot 2
#
emissionsByYearByFips <- aggregate(NEI$Emissions, by = list(NEI$year, NEI$fips), FUN=sum, na.rm=TRUE)
names(emissionsByYearByFips) <- c("year", "fips", "total")
emissionsByYear_BaltimoreCity <- emissionsByYear[emissionsByYearByFips$fips == "24510",]
png(filename = "plot2.png", width = 480, height = 480, units = "px")
plot(emissionsByYear_BaltimoreCity$year, emissionsByYear_BaltimoreCity$total/1000, type="b",
main="Baltimore City Total PM2.5 Emission From All Sources",
xlab="Year", ylab="Total Emissions (1,000 Tons)", ylim=c(0, max(emissionsByYear_BaltimoreCity$total/1000)))
dev.off()
print("Reading data files.")
NEI <- readRDS("./data/zipcontents/summarySCC_PM25.rds")
SCC <- readRDS("./data/zipcontents/Source_Classification_Code.rds")
print("Reading data files completed.")
####
#
# Plot 2
#
emissionsByYearByFips <- aggregate(NEI$Emissions, by = list(NEI$year, NEI$fips), FUN=sum, na.rm=TRUE)
names(emissionsByYearByFips) <- c("year", "fips", "total")
emissionsByYear_BaltimoreCity <- emissionsByYearByFips[emissionsByYearByFips$fips == "24510",]
png(filename = "plot2.png", width = 480, height = 480, units = "px")
plot(emissionsByYear_BaltimoreCity$year, emissionsByYear_BaltimoreCity$total/1000, type="b",
main="Baltimore City Total PM2.5 Emission From All Sources",
xlab="Year", ylab="Total Emissions (1,000 Tons)", ylim=c(0, max(emissionsByYear_BaltimoreCity$total/1000)))
dev.off()
emissionsByYearFipsType <- aggregate(NEI$Emissions, by = list(NEI$year, NEI$fips, NEI$type), FUN=sum, na.rm=TRUE)
str(emissionsByYearFipsType)
names(emissionsByYearFipsType) <- c("year", "fips", "type", "total")
str(emissionsByYearFipsType)
emissionsByYearType_BaltimoreCity <- emissionsByYearFipsType[emissionsByYearFipsType$fips == "24510",]
emissionsByYearType_BaltimoreCity
